"""
Simplified Dora PrimeSpeech Node - Main entry point
High-quality text-to-speech using GPT-SoVITS technology.
"""

import time
import os
import sys
import traceback
import json
import numpy as np
import pyarrow as pa
from dora import Node
from pathlib import Path
from typing import Optional

from .config import PrimeSpeechConfig, VOICE_CONFIGS
from .model_manager import ModelManager
from .moyoyo_tts_wrapper_streaming_fix import StreamingMoYoYoTTSWrapper as MoYoYoTTSWrapper, MOYOYO_AVAILABLE

# Add common logging to path
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', 'dora-common'))
from dora_common.logging import send_log as common_send_log, get_log_level_from_env


def send_log(node, level, message, config_level="INFO"):
    """Wrapper for backward compatibility during migration to common logging."""
    # Convert old format to new format
    common_send_log(node, level, message, "primespeech-tts", config_level)


def validate_language_config(lang_code, param_name, node, log_level):
    """Validate language configuration and provide helpful error messages"""
    # Valid language codes for MoYoYo TTS v2
    VALID_LANGUAGES = ["auto", "auto_yue", "en", "zh", "ja", "yue", "ko",
                      "all_zh", "all_ja", "all_yue", "all_ko"]

    if lang_code in VALID_LANGUAGES:
        return lang_code

    # Invalid language code - log error
    main_error = f"INVALID {param_name}: '{lang_code}' is NOT a valid language!"
    send_log(node, "ERROR", main_error, log_level)

    # Check for common mistakes and suggest corrections
    if lang_code.lower() == "cn":
        hint = "Did you mean 'zh' for Chinese? Use 'zh' not 'cn'!"
        send_log(node, "ERROR", hint, log_level)
    elif lang_code.lower() == "chinese":
        hint = "Use 'zh' for Chinese, not 'chinese'!"
        send_log(node, "ERROR", hint, log_level)
    elif lang_code.lower() == "english":
        hint = "Use 'en' for English, not 'english'!"
        send_log(node, "ERROR", hint, log_level)

    valid_msg = f"Valid languages: {', '.join(VALID_LANGUAGES)}"
    send_log(node, "ERROR", valid_msg, log_level)
    send_log(node, "ERROR", f"TTS will fail until you fix {param_name}!", log_level)

    # Return the invalid code as-is (will cause TTS to fail with clear error)
    return lang_code


def _validate_models_path(logger, models_env_var="PRIMESPEECH_MODEL_DIR") -> Optional[Path]:
    """Validate that required model directory exists and contains MoYoYo subdir.
    Returns the resolved path if valid, else None.
    """
    raw = os.environ.get(models_env_var)
    if not raw:
        logger("ERROR", f"Missing {models_env_var} environment variable; TTS cannot load models")
        return None
    # Expand env vars (e.g., $HOME) and user (~)
    base = Path(os.path.expanduser(os.path.expandvars(raw)))
    if not base.exists():
        logger("ERROR", f"{models_env_var} points to non-existent path: {base}")
        return None
    moyoyo_dir = base / "moyoyo"
    if not moyoyo_dir.exists():
        logger("WARNING", f"Expected models under: {moyoyo_dir} (directory missing)")
    return base


def main():
    """Main entry point for PrimeSpeech node"""

    node = Node()
    config = PrimeSpeechConfig()

    # Get voice configuration
    voice_name = config.VOICE_NAME
    if voice_name not in VOICE_CONFIGS:
        send_log(node, "ERROR", f"Unknown voice: {voice_name}. Available: {list(VOICE_CONFIGS.keys())}", config.LOG_LEVEL)
        voice_name = "Doubao"

    voice_config = VOICE_CONFIGS[voice_name]

    # Override with environment variables if provided
    if config.PROMPT_TEXT:
        voice_config["prompt_text"] = config.PROMPT_TEXT

    # Validate and set text language
    send_log(node, "DEBUG", f"TEXT_LANG from env: '{config.TEXT_LANG}'", config.LOG_LEVEL)
    if config.TEXT_LANG:
        validated_text_lang = validate_language_config(
            config.TEXT_LANG, "TEXT_LANG", node, config.LOG_LEVEL)
        voice_config["text_lang"] = validated_text_lang
        send_log(node, "DEBUG", f"Validated TEXT_LANG: '{validated_text_lang}'", config.LOG_LEVEL)

    # Validate and set prompt language
    send_log(node, "DEBUG", f"PROMPT_LANG from env: '{config.PROMPT_LANG}'", config.LOG_LEVEL)
    if config.PROMPT_LANG:
        validated_prompt_lang = validate_language_config(
            config.PROMPT_LANG, "PROMPT_LANG", node, config.LOG_LEVEL)
        voice_config["prompt_lang"] = validated_prompt_lang
        send_log(node, "DEBUG", f"Validated PROMPT_LANG: '{validated_prompt_lang}'", config.LOG_LEVEL)
    
    # Add inference parameters
    effective_speed_factor = (
        config.SPEED_FACTOR
        if config.SPEED_FACTOR is not None
        else voice_config.get("speed_factor", 1.0)
    )

    if config.SPEED_FACTOR is not None:
        send_log(
            node,
            "INFO",
            f"Overriding speed_factor via env to {effective_speed_factor}",
            config.LOG_LEVEL,
        )

    effective_fragment_interval = (
        config.FRAGMENT_INTERVAL
        if config.FRAGMENT_INTERVAL is not None
        else voice_config.get("fragment_interval")
    )
    if config.FRAGMENT_INTERVAL is not None:
        send_log(
            node,
            "INFO",
            f"Overriding fragment_interval via env to {effective_fragment_interval}",
            config.LOG_LEVEL,
        )

    voice_config.update({
        "top_k": config.TOP_K,
        "top_p": config.TOP_P,
        "temperature": config.TEMPERATURE,
        "speed_factor": effective_speed_factor,
        "batch_size": config.BATCH_SIZE,
        "seed": config.SEED,
        "text_split_method": config.TEXT_SPLIT_METHOD,
        "split_bucket": config.SPLIT_BUCKET,
        "return_fragment": config.RETURN_FRAGMENT,
        "use_gpu": config.USE_GPU,
        "device": config.DEVICE,
        "sample_rate": config.SAMPLE_RATE,
    })
    if effective_fragment_interval is not None:
        voice_config["fragment_interval"] = effective_fragment_interval
    
    # Initialize model manager
    model_manager = ModelManager(config.get_models_dir())
    
    send_log(node, "INFO", "PrimeSpeech Node initialized", config.LOG_LEVEL)
    
    if MOYOYO_AVAILABLE:
        send_log(node, "INFO", "‚úì MoYoYo TTS engine available", config.LOG_LEVEL)
    else:
        send_log(node, "WARNING", "‚ö†Ô∏è  MoYoYo TTS not fully available", config.LOG_LEVEL)
    
    # Log the configuration being used
    send_log(node, "INFO", f"Voice: {voice_name}", config.LOG_LEVEL)
    send_log(node, "INFO", f"Text Language: {voice_config.get('text_lang', 'auto')} (configured: {config.TEXT_LANG})", config.LOG_LEVEL)
    send_log(node, "INFO", f"Prompt Language: {voice_config.get('prompt_lang', 'auto')} (configured: {config.PROMPT_LANG})", config.LOG_LEVEL)

    # Print to stdout for immediate visibility
    speed_factor_value = voice_config.get('speed_factor')
    fragment_interval_value = voice_config.get('fragment_interval')
    send_log(
        node,
        "INFO",
        f"Speed Factor: {speed_factor_value} (env override: {config.SPEED_FACTOR_OVERRIDE is not None})",
        config.LOG_LEVEL,
    )
    if fragment_interval_value is not None:
        send_log(
            node,
            "INFO",
            f"Fragment Interval: {fragment_interval_value} (env override: {config.FRAGMENT_INTERVAL_OVERRIDE is not None})",
            config.LOG_LEVEL,
        )
    send_log(node, "INFO", f"Device: {config.DEVICE}", config.LOG_LEVEL)

    # Validate the final configuration
    final_text_lang = voice_config.get('text_lang', 'auto')
    final_prompt_lang = voice_config.get('prompt_lang', 'auto')

    VALID_LANGUAGES = ["auto", "auto_yue", "en", "zh", "ja", "yue", "ko",
                      "all_zh", "all_ja", "all_yue", "all_ko"]

    if final_text_lang not in VALID_LANGUAGES:
        send_log(node, "ERROR",
                f"CRITICAL: text_lang '{final_text_lang}' is not valid! "
                f"This will cause TTS to fail. Please fix your configuration.",
                config.LOG_LEVEL)

    if final_prompt_lang not in VALID_LANGUAGES:
        send_log(node, "ERROR",
                f"CRITICAL: prompt_lang '{final_prompt_lang}' is not valid! "
                f"This will cause TTS to fail. Please fix your configuration.",
                config.LOG_LEVEL)
    
    # Initialize TTS engine
    tts_engine: Optional[MoYoYoTTSWrapper] = None
    model_loaded = False

    # Pre-initialize TTS engine to avoid first-call delay
    try:
        send_log(node, "INFO", "Pre-initializing TTS engine...", config.LOG_LEVEL)
        start_time = time.time()

        # Validate models directory early
        _validate_models_path(lambda lvl, msg: send_log(node, lvl, msg, config.LOG_LEVEL))

        # Initialize TTS wrapper
        moyoyo_voice = voice_name.lower().replace(" ", "")
        device = "cuda" if config.USE_GPU and config.DEVICE.startswith("cuda") else "cpu"
        enable_streaming = config.RETURN_FRAGMENT if hasattr(config, 'RETURN_FRAGMENT') else False

        tts_engine = MoYoYoTTSWrapper(
            voice=moyoyo_voice,
            device=device,
            enable_streaming=enable_streaming,
            chunk_duration=0.3,
            voice_config=voice_config,
            logger_func=lambda level, msg: send_log(node, level, msg, config.LOG_LEVEL)
        )

        # Verify initialization
        if tts_engine is None or not hasattr(tts_engine, 'tts') or tts_engine.tts is None:
            raise RuntimeError("TTS engine initialization failed - internal TTS is None")

        model_loaded = True
        init_time = time.time() - start_time
        send_log(node, "INFO", f"TTS engine pre-initialized in {init_time:.2f}s", config.LOG_LEVEL)
        send_log(node, "INFO", "Ready to synthesize speech", config.LOG_LEVEL)

    except Exception as init_err:
        send_log(node, "WARNING", f"Failed to pre-initialize TTS engine: {init_err}", config.LOG_LEVEL)
        send_log(node, "WARNING", "TTS engine will be initialized on first use", config.LOG_LEVEL)
        send_log(node, "DEBUG", f"Traceback: {traceback.format_exc()}", config.LOG_LEVEL)
        model_loaded = False
        tts_engine = None

    # Statistics
    total_syntheses = 0
    total_duration = 0
    
    for event in node:
        if event["type"] == "INPUT":
            input_id = event["id"]
            
            if input_id == "text":
                # Get text to synthesize
                text = event["value"][0].as_py()
                metadata = event.get("metadata", {})

                # DEBUG: Log what we received
                send_log(node, "DEBUG", f"RECEIVED text: '{text}' (len={len(text)}, repr={repr(text)}, type={type(text).__name__})", config.LOG_LEVEL)

                segment_index = int(metadata.get("segment_index", -1))

                # Skip if text is only punctuation or whitespace
                text_stripped = text.strip()
                if not text_stripped or all(c in '„ÄÇÔºÅÔºü.!?,Ôºå„ÄÅÔºõÔºö""''ÔºàÔºâ„Äê„Äë„Ää„Äã\n\r\t ' for c in text_stripped):
                    send_log(node, "DEBUG", f"SKIPPED - text is only punctuation/whitespace: '{text}'", config.LOG_LEVEL)
                    # Send segment_complete without audio
                    # Send segment skipped signal
                    node.send_output(
                        "segment_complete",
                        pa.array(["skipped"]),
                        metadata={
                            "question_id": metadata.get("question_id", "default"),  # Pass through question_id
                            "session_status": metadata.get("session_status", "unknown"),  # Pass through session status
                        }
                    )

                    # For empty text, just skip processing but send segment_complete for flow control
                    send_log(node, "DEBUG", f"Skipping empty segment", config.LOG_LEVEL)

                    # Send segment_complete to maintain proper flow control, passing through ALL metadata
                    node.send_output(
                        "segment_complete",
                        pa.array(["empty"]),
                        metadata=metadata if metadata else {}
                    )
                    continue

                send_log(node, "DEBUG", f"Processing segment {segment_index + 1} (len={len(text)})", config.LOG_LEVEL)

                # Load models if not loaded
                if not model_loaded:
                    send_log(node, "DEBUG", "Loading models for the first time...", config.LOG_LEVEL)
                    # Validate models directory early so failures are visible
                    _validate_models_path(lambda lvl, msg: send_log(node, lvl, msg, config.LOG_LEVEL))

                    try:
                        # Always use PRIMESPEECH_MODEL_DIR
                        send_log(node, "DEBUG", "Using PRIMESPEECH_MODEL_DIR for models...", config.LOG_LEVEL)
                        # Initialize TTS engine
                        # Convert voice name to lowercase and remove spaces for MoYoYo compatibility
                        moyoyo_voice = voice_name.lower().replace(" ", "")
                        device = "cuda" if config.USE_GPU and config.DEVICE.startswith("cuda") else "cpu"

                        enable_streaming = config.RETURN_FRAGMENT if hasattr(config, 'RETURN_FRAGMENT') else False

                        # Initialize TTS wrapper using PRIMESPEECH_MODEL_DIR
                        tts_engine = MoYoYoTTSWrapper(
                            voice=moyoyo_voice,
                            device=device,
                            enable_streaming=enable_streaming,
                            chunk_duration=0.3,
                            voice_config=voice_config,
                            logger_func=lambda level, msg: send_log(node, level, msg, config.LOG_LEVEL)
                        )

                        # Check if initialization succeeded
                        if tts_engine is None or not hasattr(tts_engine, 'tts') or tts_engine.tts is None:
                            send_log(node, "ERROR", "TTS engine initialization failed!", config.LOG_LEVEL)
                            send_log(node, "ERROR", "TTS wrapper exists but internal TTS is None", config.LOG_LEVEL)
                        else:
                            send_log(node, "DEBUG", "TTS engine initialized successfully", config.LOG_LEVEL)
                        model_loaded = True
                        send_log(node, "DEBUG", "TTS engine ready", config.LOG_LEVEL)
                    except Exception as init_err:
                        send_log(node, "ERROR", f"TTS init error: {init_err}", config.LOG_LEVEL)
                        send_log(node, "ERROR", f"Traceback: {traceback.format_exc()}", config.LOG_LEVEL)
                        # Mark as not loaded and send error completion without audio
                        model_loaded = False
                        # Send error completion signal
                        node.send_output(
                            "segment_complete",
                            pa.array(["error"]),
                            metadata={
                                "session_id": session_id,
                                "request_id": request_id,
                                "question_id": metadata.get("question_id", "default"),  # Pass through question_id
                                "session_status": "error",  # Explicit error status
                                "error": str(init_err),
                                "error_stage": "init"
                            }
                        )

                        # Session end signals are now handled by the text segmenter, not TTS
                        # The text segmenter will handle error cases appropriately
                        send_log(node, "ERROR", f"TTS initialization error for question_id {metadata.get('question_id', 'default')}: {init_err}", config.LOG_LEVEL)
                        # Skip this event since we cannot synthesize
                        continue
                
                # Synthesize speech
                start_time = time.time()
                
                try:
                    # Check if TTS engine is available
                    if tts_engine is None:
                        send_log(node, "ERROR", "Cannot synthesize - TTS engine is None!", config.LOG_LEVEL)
                        raise RuntimeError("TTS engine not initialized")
                    
                    if hasattr(tts_engine, 'tts') and tts_engine.tts is None:
                        send_log(node, "ERROR", "Cannot synthesize - internal TTS is None!", config.LOG_LEVEL)
                        raise RuntimeError("Internal TTS engine not initialized")
                    
                    language = voice_config.get("text_lang", "zh")
                    speed = voice_config.get("speed_factor", 1.0)
                    fragment_interval = voice_config.get("fragment_interval")
                    
                    if hasattr(tts_engine, 'enable_streaming') and tts_engine.enable_streaming:
                        # Streaming synthesis
                        send_log(node, "DEBUG", "Using streaming synthesis...", config.LOG_LEVEL)
                        fragment_num = 0
                        total_audio_duration = 0
                        
                        if fragment_interval is not None:
                            tts_engine.optimization_config["fragment_interval"] = fragment_interval

                        for sample_rate, audio_fragment in tts_engine.synthesize_streaming(text, language=language, speed=speed):
                            fragment_num += 1
                            fragment_duration = len(audio_fragment) / sample_rate
                            total_audio_duration += fragment_duration

                            # Guard against empty fragments
                            if audio_fragment is None or len(audio_fragment) == 0:
                                send_log(node, "WARNING", f"Skipping empty audio fragment {fragment_num}", config.LOG_LEVEL)
                            else:
                                # Ensure type is float32 for consistency
                                if audio_fragment.dtype != np.float32:
                                    audio_fragment = audio_fragment.astype(np.float32)
                                node.send_output(
                                    "audio",
                                    pa.array([audio_fragment]),
                                    metadata={
                                        "question_id": metadata.get("question_id", "default"),  # Pass through question_id
                                        "session_status": metadata.get("session_status", "unknown"),  # Pass through session status
                                        "sample_rate": sample_rate,
                                        "duration": fragment_duration,
                                    }
                                )
                        
                        synthesis_time = time.time() - start_time
                        send_log(node, "INFO", f"Streamed {fragment_num} fragments, {total_audio_duration:.2f}s audio in {synthesis_time:.3f}s", config.LOG_LEVEL)
                        # If nothing was streamed, mark as error to avoid hanging clients
                        if fragment_num == 0:
                            raise RuntimeError("No audio fragments produced during streaming synthesis")
                        
                    else:
                        # Batch synthesis
                        synth_kwargs = {
                            "language": language,
                            "speed": speed,
                        }
                        if fragment_interval is not None:
                            synth_kwargs["fragment_interval"] = fragment_interval

                        sample_rate, audio_array = tts_engine.synthesize(text, **synth_kwargs)
                        
                        synthesis_time = time.time() - start_time
                        audio_duration = len(audio_array) / sample_rate
                        if audio_array is None or len(audio_array) == 0:
                            raise RuntimeError("TTS returned empty audio array")
                        # Normalize dtype
                        if audio_array.dtype != np.float32:
                            audio_array = audio_array.astype(np.float32)
                        
                        total_syntheses += 1
                        total_duration += audio_duration
                        
                        send_log(node, "DEBUG", f"Synthesized: {audio_duration:.2f}s audio in {synthesis_time:.3f}s", config.LOG_LEVEL)

                        # Send audio output with segment counting metadata
                        node.send_output(
                            "audio",
                            pa.array([audio_array]),
                            metadata={
                                "question_id": metadata.get("question_id", "default"),  # Pass through question_id
                                "session_status": metadata.get("session_status", "unknown"),  # Pass through session status
                                "sample_rate": sample_rate,
                                "duration": audio_duration,
                            }
                        )
                        send_log(node, "INFO", f"üì§ AUDIO SENT: {len(audio_array)} samples ({audio_duration:.2f}s)", config.LOG_LEVEL)

                    # Send segment completion signal
                    node.send_output(
                        "segment_complete",
                        pa.array(["completed"]),
                        metadata={
                            "question_id": metadata.get("question_id", "default"),  # Pass through question_id
                            "session_status": metadata.get("session_status", "unknown"),  # Pass through session status
                        }
                    )
                    send_log(node, "DEBUG", f"üì§ SEGMENT_COMPLETE sent", config.LOG_LEVEL)

                    # Session end signals are now handled by the text segmenter, not TTS
                    # The text segmenter detects session end from session_status metadata and sends appropriate signals
                    session_status = metadata.get("session_status", "unknown")
                    if session_status in ["completed", "finished", "ended", "final"]:
                        send_log(node, "INFO", f"TTS completed session for question_id {metadata.get('question_id', 'default')} with status: {session_status}", config.LOG_LEVEL)

                except Exception as e:
                    error_details = traceback.format_exc()

                    # Check for specific language-related errors
                    if "assert text_lang" in str(e) or "assert prompt_lang" in str(e) or "AssertionError" in str(e.__class__.__name__):
                        send_log(node, "ERROR", "="*60, config.LOG_LEVEL)
                        send_log(node, "ERROR", "CRITICAL: Language configuration error detected!", config.LOG_LEVEL)
                        send_log(node, "ERROR", f"TEXT_LANG: '{language}' (from config: '{config.TEXT_LANG}')", config.LOG_LEVEL)
                        send_log(node, "ERROR", f"PROMPT_LANG: '{voice_config.get('prompt_lang', 'auto')}' (from config: '{config.PROMPT_LANG}')", config.LOG_LEVEL)
                        send_log(node, "ERROR", "Valid languages: auto, auto_yue, zh, en, ja, ko, yue, all_zh, all_ja, all_yue, all_ko", config.LOG_LEVEL)
                        send_log(node, "ERROR", "Common mistakes: 'cn' should be 'zh', 'chinese' should be 'zh'", config.LOG_LEVEL)
                        send_log(node, "ERROR", "Fix your configuration and restart!", config.LOG_LEVEL)
                        send_log(node, "ERROR", "="*60, config.LOG_LEVEL)

                    send_log(node, "ERROR", f"Synthesis error: {e}", config.LOG_LEVEL)
                    send_log(node, "ERROR", f"Traceback: {error_details}", config.LOG_LEVEL)
                    
                    # Do NOT send invalid audio on error; only notify completion with error
                    # Send error completion signal
                    node.send_output(
                        "segment_complete",
                        pa.array(["error"]),
                        metadata={
                            "question_id": metadata.get("question_id", "default"),  # Pass through question_id
                            "session_status": "error",  # Explicit error status
                            "error": str(e),
                            "error_stage": "synthesis"
                        }
                    )
                    question_id = metadata.get('question_id', 0)
                    if isinstance(question_id, (int, float)):
                        send_log(node, "ERROR", f"Sent error segment_complete with enhanced question_id={question_id}", config.LOG_LEVEL)
                    else:
                        send_log(node, "ERROR", f"Sent error segment_complete with question_id={question_id}", config.LOG_LEVEL)

                    # Session end signals are now handled by the text segmenter, not TTS
                    # The text segmenter will handle error cases appropriately based on session_status metadata
                    send_log(node, "ERROR", f"TTS synthesis error for question_id {metadata.get('question_id', 'default')}: {e}", config.LOG_LEVEL)

            elif input_id == "control":
                # Handle control commands
                command = event["value"][0].as_py()
                
                if command == "reset":
                    send_log(node, "INFO", "[PrimeSpeech] RESET received", config.LOG_LEVEL)
                    # Note: Can't actually stop ongoing synthesis, but it's OK
                    # because we only process one segment at a time now
                    send_log(node, "INFO", "[PrimeSpeech] Reset acknowledged", config.LOG_LEVEL)
                
                elif command == "stats":
                    send_log(node, "INFO", f"Total syntheses: {total_syntheses}", config.LOG_LEVEL)
                    send_log(node, "INFO", f"Total audio duration: {total_duration:.1f}s", config.LOG_LEVEL)
        
        elif event["type"] == "STOP":
            break
    
    send_log(node, "INFO", "PrimeSpeech node stopped", config.LOG_LEVEL)


if __name__ == "__main__":
    main()
