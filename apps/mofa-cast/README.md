# MoFA Cast

> Transform your **optimized scripts** into multi-voice podcast audio with local TTS

**Version**: 0.6.3
**Status**: ğŸ‰ Production-Ready with Multi-Voice Support
**Last Updated**: 2026-01-17

## Overview

MoFA Cast is a **local multi-voice text-to-speech (TTS) tool** that converts your already-optimized podcast scripts into professional audio with distinct speaker voices through **local** multi-voice TTS synthesis using PrimeSpeech engine.

## Project Philosophy

**Local-First Development**: All core functionality should work locally without requiring external API keys or cloud services. This ensures:
- âœ… Complete privacy and data ownership
- âœ… No ongoing costs for users
- âœ… Works offline
- âœ… Faster response times (no network latency)

## Project Structure

```
apps/mofa-cast/
â”œâ”€â”€ Cargo.toml                   # Dependencies
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ ARCHITECTURE.md              # Technical architecture
â”œâ”€â”€ CHANGELOG.md                 # Version history
â”œâ”€â”€ dataflow/                    # Dora dataflow configs
â”‚   â””â”€â”€ multi-voice-batch-tts.yml     # Multi-voice TTS pipeline
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ USER_GUIDE.md            # User documentation
â”‚   â”œâ”€â”€ TROUBLESHOOTING.md       # Issue resolution
â”‚   â”œâ”€â”€ DEVELOPMENT.md           # Developer guide
â”‚   â”œâ”€â”€ HISTORY.md               # Development history
â”‚   â””â”€â”€ SCRIPT_OPTIMIZATION_GUIDE.md  # AI script optimization
â”œâ”€â”€ test_samples/                # Test files
â”‚   â”œâ”€â”€ sample_plain.txt
â”‚   â”œâ”€â”€ sample_json.json
â”‚   â””â”€â”€ sample_markdown.md
â””â”€â”€ src/
    â”œâ”€â”€ lib.rs                   # MoFA Studio app integration
    â”œâ”€â”€ screen/                  # UI components
    â”‚   â”œâ”€â”€ mod.rs
    â”‚   â”œâ”€â”€ main.rs              # Main UI screen
    â”‚   â””â”€â”€ design.rs            # Live design definitions
    â”œâ”€â”€ transcript_parser.rs     # Parse transcript formats
    â”œâ”€â”€ script_templates.rs      # Pre-built templates
    â”œâ”€â”€ recent_files.rs          # Recent files management
    â”œâ”€â”€ tts_batch.rs             # TTS engine abstraction
    â”œâ”€â”€ audio_mixer.rs           # Audio mixing and export
    â”œâ”€â”€ dora_integration.rs      # Dora dataflow integration
    â””â”€â”€ dora_process_manager.rs  # Dora lifecycle management
```

**Legend**: âœ… = Completed, â³ = Planned

## Features

- **Import**: Load optimized podcast scripts (Plain text, JSON, Markdown)
- **Edit**: Make minor adjustments to imported scripts
- **Synthesize**: Multi-voice batch TTS with Dora dataflow using PrimeSpeech (local, high quality)
- **Export**: Audio mixing and WAV export âœ…
- **Monitor**: Real-time log viewer with filtering

## What MoFA Cast Does NOT Do

- âŒ **Script optimization** - Use ChatGPT, Claude, or other AI tools (see [SCRIPT_OPTIMIZATION_GUIDE.md](docs/SCRIPT_OPTIMIZATION_GUIDE.md))
- âŒ **LLM API integration** - No OpenAI/Claude API calls
- âŒ **Automated content generation** - Script optimization is external

**Why?** External AI tools (ChatGPT, Claude) provide:
- âœ… Zero cost (no API fees)
- âœ… Better quality (direct interaction with latest models)
- âœ… More flexibility (iterate until perfect)
- âœ… Access to GPT-4o, Claude 4, etc.

MoFA Cast focuses on what it does best: **multi-voice TTS synthesis**.

## Current Status

### âœ… Completed (2026-01-14)

**Latest Release**: v0.5.0 - Multi-Voice Support & UI Enhancements

#### Infrastructure & Setup
- âœ… Project structure created and configured
- âœ… Dependencies configured (Cargo.toml)
- âœ… MofaApp trait implemented
- âœ… Documentation organized in `docs/` directory

#### P0.1 - Transcript Parsing âœ…
- âœ… Implemented `TranscriptParser` trait
- âœ… Created 3 parsers: PlainText, JSON, Markdown
- âœ… Implemented `ParserFactory` with auto-detection
- âœ… Added speaker statistics extraction
- âœ… All unit tests passing (5/5)
- âœ… ~672 lines of production code

#### P0.2 - UI Integration âœ…
- âœ… Integrated parser with CastScreen
- âœ… Added file import button handler
- âœ… Display parsed transcript in original editor
- âœ… Show speaker statistics in left panel
- âœ… Update file info with message/speaker count
- âœ… Created test sample files
- âœ… ~590 lines total in screen.rs

#### P0.3 - AI Script Refinement âœ…
- âœ… Implemented `ScriptRefiner` trait with async/await
- âœ… Created `OpenAiRefiner` with OpenAI API integration
- âœ… Implemented `MockRefiner` for testing without API
- âœ… Added `PromptTemplates` for structured prompts
- âœ… Comprehensive error handling (8 error types)
- âœ… Integrated with CastScreen Refine button
- âœ… Show progress indicator during refinement
- âœ… Display refined script in editable editor
- âœ… All unit tests passing (7/7: 5 parser + 2 refiner)
- âœ… ~485 lines of production code

**Key Features**:
- Trait-based architecture for extensibility
- Multiple AI provider support (OpenAI ready, Claude stub)
- Mock refiner enables testing without API costs
- Async/await with tokio runtime integration
- Streaming support for real-time progress updates

#### P0.4 - Batch TTS Synthesis âœ…
- âœ… Implemented `TtsEngine` trait for extensibility
- âœ… Created `ScriptSegmenter` to parse scripts by speaker
- âœ… Implemented `BatchTtsSynthesizer` with parallel processing
- âœ… Created `MockTtsEngine` for testing without TTS engine
- âœ… Comprehensive error handling (7 error types)
- âœ… Integrated with CastScreen Synthesize button
- âœ… Progress tracking during synthesis
- âœ… Audio file management (organized by speaker)
- âœ… All unit tests passing (11/11: 5 parser + 2 refiner + 4 TTS)
- âœ… ~580 lines of production code
- âœ… **Removed OpenAI TTS (cloud-based, violates local-first principle)**

**Key Features**:
- Trait-based TTS engine architecture (extensible for Dora, Kokoro, PrimeSpeech)
- Script segmentation by speaker with regex pattern matching
- Parallel async synthesis with configurable concurrency
- Mock TTS engine creates valid WAV files for testing
- Progress callbacks for real-time UI updates
- Organized output structure (output_dir/speaker/segment_NNN.wav)

**ğŸš¨ Important**: Currently using `MockTtsEngine` (generates test tones).
Next step: Integrate `dora-kokoro-tts` for real local TTS synthesis.

#### P0.5 - Audio Mixing and Export âœ…
- âœ… Implemented `AudioMixer` with WAV file handling
- âœ… Created `WavHeader` structure for parsing/generating WAV files
- âœ… Implemented audio concatenation with silence insertion
- âœ… Volume normalization interface (configurable)
- âœ… Metadata support structure (title, artist, album, etc.)
- âœ… Integrated with CastScreen Export button
- âœ… Organized segment collection from TTS output
- âœ… All unit tests passing (16/16: 5 parser + 2 refiner + 4 TTS + 5 mixer)
- âœ… ~540 lines of production code

**Key Features**:
- Direct WAV file manipulation without external dependencies
- Configurable silence between segments (default 0.5s)
- Format validation (sample rate, channels, bits per sample)
- Automatic segment ordering by filename
- Duration calculation and file size reporting

#### P0.6 - Dora Dataflow Integration âœ…
- âœ… Created `dataflow/batch-tts.yml` for TTS pipeline
- âœ… Implemented `DoraIntegration` with worker thread
- âœ… Integrated `DynamicNodeDispatcher` for bridge management
- âœ… Refactored `handle_synthesize_audio()` to use Dora dataflow
- âœ… Added environment variable configuration (BACKEND, VOICE, LANGUAGE, SPEED)
- âœ… Implemented event polling for progress updates
- âœ… Added ScriptSegment for dataflow communication
- âœ… ~320 lines of dora integration code
- âœ… Build successful with 14 warnings (non-breaking)

**Key Features**:
- Dataflow lifecycle management (start/stop)
- Async communication via command/event channels
- Timer-based event polling (100ms interval)
- Integration with dora-kokoro-tts for local TTS
- Extensible architecture for additional TTS engines
- Consistent with mofa-fm architecture pattern

**Dataflow Nodes**:
- `text-input`: Dynamic node receiving script segments
- `text-segmenter`: Splits text into TTS-friendly chunks
- `kokoro-tts`: Local TTS synthesis (Kokoro-82M)
- `mofa-cast-controller`: Dynamic node returning audio to UI

#### P0.7 - Audio Collection and Export âœ…
- âœ… Implemented audio segment collection in `poll_dora_events()`
- âœ… Added WAV file writing from AudioData (f32 â†’ i16 conversion)
- âœ… Store collected segments with metadata (path, speaker, duration)
- âœ… Track synthesis progress (received/expected segments)
- âœ… Auto-enable export when all segments received
- âœ… Refactored `handle_export_audio()` to use collected segments
- âœ… Integration with audio_mixer for final export
- âœ… Added comprehensive test documentation (TTS_WORKFLOW_TEST.md)
- âœ… ~200 lines of audio collection code

**Key Features**:
- Real-time audio segment collection from Dora events
- Automatic WAV file generation with proper headers
- Progress tracking and UI updates during synthesis
- Segments organized by speaker with sequential naming
- Duration calculation and validation
- Complete export workflow (collect â†’ mix â†’ save)
- End-to-end testing guide with troubleshooting

**Audio Output**:
- Individual segments: `output/mofa-cast/dora/segment_XXX_speaker.wav`
- Final podcast: `output/mofa-cast/podcast.wav`
- Format: 16-bit PCM WAV, 22050 Hz (or native rate), mono
- Segments separated by 0.5s silence

#### P1.1 - Multi-Voice Support âœ…
- âœ… Implemented dynamic voice routing with `dora-voice-router`
- âœ… Smart voice assignment (hostâ†’Luo Xiang, guest1â†’Ma Yun, guest2â†’Ma Baoguo)
- âœ… Speaker normalization (merges duplicate speaker names)
- âœ… Created `multi-voice-batch-tts.yml` dataflow with 3 parallel PrimeSpeech TTS nodes
- âœ… Automatic voice mapping UI in CastScreen
- âœ… 100% success rate in testing (10/10 segments with distinct voices)
- âœ… ~200 lines of voice router code + dataflow configuration

**Key Features**:
- JSON-based segment format: `{"speaker": "...", "text": "...", "voice_name": "...", "speed": 1.0}`
- Routes to 3 parallel PrimeSpeech TTS nodes based on voice_name
- Zero-configuration user experience with automatic role-based mapping
- Applied during TTS sending (doesn't modify UI text)
- No slowdown (~4s per segment, same as single-voice)

#### P1.2 - UI Enhancements (Partial) âœ…
- âœ… Implemented real-time log viewer with collapsible panel
- âœ… Added log level filtering (ALL/INFO/WARN/ERROR)
- âœ… Improved layout: left panel 300â†’200px, compact spacing
- âœ… Added application icon (ğŸ™ï¸ studio microphone)
- âœ… Enhanced dropdown styling with hover effects
- âœ… Fixed text input auto-wrap and scrolling
- âœ… Fixed 3 bugs (stack overflow, scroll component, text color)
- âœ… ~400 lines of UI improvements in screen.rs

**Key Features**:
- Collapsible log panel (320px width, toggle button)
- Markdown rendering for formatted logs
- Auto-capture of all Dora events
- Fixed color schemes for light theme
- Text input auto-wrap and scrolling
- Compact layout design (28px vertical space saved)

**Bugs Fixed**:
1. Stack overflow in log initialization (infinite recursion)
2. Scroll component error (changed to ScrollYView)
3. White text on light background (fixed font_color)

## Quick Start

### 1. Build and Run

```bash
# Build mofa-cast
cargo build --release --package mofa-cast

# Start mofa-studio-shell
./target/release/mofa-studio-shell
```

### 2. Prepare Your Script

**Step 1**: Use ChatGPT or Claude to optimize your chat transcript

**Step 2**: Save the optimized script as `script.txt`, `script.md`, or `script.json`

**Step 3**: Use this format in your script:
```
host: Welcome to today's episode...
guest1: Thanks for having me...
guest2: I'm excited to be here...
```

ğŸ’¡ **See [SCRIPT_OPTIMIZATION_GUIDE.md](docs/SCRIPT_OPTIMIZATION_GUIDE.md) for recommended prompts and workflows**

### 3. Generate Audio

1. Click **MoFA Cast** icon in sidebar
2. **Import**: Select format â†’ Click Import â†’ Choose your script file
3. **Edit** (optional): Make minor adjustments in the script editor
4. **Synthesize**: Click "Synthesize Audio"
   - Voices are auto-assigned: hostâ†’Luo Xiang, guest1â†’Ma Yun, guest2â†’Ma Baoguo
   - Monitor progress in real-time log viewer
5. **Export**: Click "Export Audio" to create final podcast file

**Expected Output**: `output/mofa-cast/podcast.wav`

**Documentation**:
- **Testing**: [docs/TTS_WORKFLOW_TEST.md](docs/TTS_WORKFLOW_TEST.md)
- **File Dialog Issues**: [docs/FILE_DIALOG_TROUBLESHOOTING.md](docs/FILE_DIALOG_TROUBLESHOOTING.md)

## TTS Engine Options

### âœ… PrimeSpeech (Recommended - Multi-Voice)
**Local multi-voice TTS engine via dora-primespeech**

**Features**:
- ğŸ­ **Multi-Voice**: Support for 3+ distinct voices in single podcast
- ğŸŒ **Chinese Optimized**: High-quality Chinese pronunciation
- ğŸš€ **Fast**: ~4s per segment with parallel processing
- ğŸ”’ **Privacy**: 100% local, no internet required
- ğŸ’° **Free**: No API costs, no rate limits

**Available Voices**:
- Luo Xiang: Deep male voice (authoritative, host)
- Ma Yun: Energetic male voice (guest speaker)
- Ma Baoguo: Characteristic voice (distinctive style)
- More voices available in `~/.dora/models/primespeech/`

**Usage**:
```bash
# Build mofa-cast with PrimeSpeech
cargo build --release --package mofa-cast

# Start mofa-studio
./target/release/mofa-studio-shell

# In the UI:
# 1. Import a transcript with multiple speakers
# 2. Click "Refine Script" (AI enhancement)
# 3. Click "Synthesize Audio" (uses multi-voice PrimeSpeech)
#    - Voices are auto-assigned based on speaker names
#    - Monitor progress in log viewer
# 4. Export final podcast
```

**Dataflow**: Uses `dataflow/multi-voice-batch-tts.yml` with 3 parallel TTS nodes

### â³ Kokoro-82M (Deprecated - Single Voice Only)
**Legacy single-voice TTS engine**

**Status**: Replaced by PrimeSpeech for multi-voice support
- See [docs/KOKORO_TTS_GUIDE_DEPRECATED.md](docs/KOKORO_TTS_GUIDE_DEPRECATED.md)
- Still supported for single-voice use cases
- 6.6x realtime on Apple Silicon (MLX), 4.1x on CPU
- 100+ voices across EN, ZH, JA, KO languages

### â³ MockTtsEngine (Testing)
**Simple test tones for development**

**Features**:
- Generates 440Hz sine wave tones
- Creates valid WAV files for testing audio pipeline
- No external dependencies
- Useful for UI/UX testing without TTS engine

## Development Roadmap
- Metadata structure ready for future implementation

#### UI Framework
- âœ… Complete `CastScreen` widget implementation
- âœ… Split-view editor (original | refined script)
- âœ… Left panel (import section + speaker list)
- âœ… Right panel (control buttons + editor)
- âœ… Dark mode support throughout
- âœ… Custom icon (`cast.svg`) created

#### Shell Integration
- âœ… Registered in `mofa-studio-shell`
- âœ… Sidebar navigation ("MoFA Cast" button)
- âœ… Page visibility toggling
- âœ… Dark mode propagation

#### Build Status
- âœ… **Build Successful**: `cargo build --release` completed without errors
- âœ… **Tests Passing**: All 16 unit tests (5 parser + 2 refiner + 4 TTS + 5 mixer)
- âœ… Only non-critical warnings (unused imports, naming conventions)

### ğŸ‰ Core Features Complete!

#### Phase 1: Core Functionality (P0) - ALL COMPLETE âœ…
1. âœ… **Transcript Parsing** (Completed in <1 day)
   - Plain text, JSON, Markdown parsers
   - Auto-detection
2. âœ… **UI Integration** (Completed in <1 day)
   - Parser integrated with UI
   - File import handler
   - Display parsed content
3. âœ… **AI Script Refinement** (Completed in <1 day)
   - OpenAI/Claude API integration
   - Streaming responses
   - Mock refiner for testing
4. âœ… **Batch TTS Synthesis** (Completed in <1 day)
   - Script segmentation by speaker
   - Parallel async synthesis
   - Mock TTS engine for testing
5. âœ… **Audio Mixing** (Completed in <1 day)
   - WAV concatenation and export
   - Silence insertion
   - Metadata structure

**Total Time**: ~5 days estimated â†’ **Completed in <1 day!**

**ğŸš€ MVP Status**: All core features implemented and tested!
- Full pipeline: Import â†’ Parse â†’ Refine â†’ Synthesize â†’ Export
- 16 unit tests passing
- Production-ready code with comprehensive error handling
- Multi-voice support with automatic voice assignment
- Real-time log viewer for progress monitoring
- â³ **Next**: MP3 export, audio player, keyboard shortcuts (P1.2 remaining)

## Development

### TTS Integration Status
- âœ… **PrimeSpeech TTS**: Multi-voice synthesis (default, recommended)
- âœ… **Voice Router**: Automatic role-based voice mapping
- âœ… **Dora Integration**: Multi-node dataflow with parallel processing
- â³ **Kokoro-82M**: Single-voice fallback (deprecated)

**Model Installation**:
```bash
# PrimeSpeech models are stored in:
~/.dora/models/primespeech/

# Available voices:
- Luo Xiang (host)
- Ma Yun (guest1)
- Ma Baoguo (guest2)
```

## Documentation

### User Documentation
- **[User Guide](docs/USER_GUIDE.md)** - Complete usage instructions
- **[Script Optimization](docs/SCRIPT_OPTIMIZATION_GUIDE.md)** - How to optimize scripts with AI tools
- **[Troubleshooting](docs/TROUBLESHOOTING.md)** - Common issues and solutions

### Developer Documentation
- **[Architecture](ARCHITECTURE.md)** - Technical design and system architecture
- **[Development Guide](docs/DEVELOPMENT.md)** - Contributing and code organization
- **[History](docs/HISTORY.md)** - Deprecated features and development history
- **[Changelog](docs/CHANGELOG.md)** - Version history and release notes

## Build & Run

```bash
# Build the project
cd /path/to/mofa-studio
cargo build --release

# Run MoFA Studio
cargo run --release
```

Then click on **"MoFA Cast"** in the sidebar to access the application.

## Contributing

This is part of the MoFA Studio project. See main [README](../../README.md) for contribution guidelines.

## License

Apache-2.0 (same as MoFA Studio)

---

**Note**: This project is in active development. Core functionality is being implemented incrementally.
